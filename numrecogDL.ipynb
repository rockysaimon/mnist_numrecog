{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST DATASET NUM RECOGNITION BY HANDWRITTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import numpy as np #sirve para manejar arreglos muy grandes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for f in list_files(mnist_path):print(f)\n",
    "#verifico que mi metodo funcione, y me muestre los archivos\n",
    "#deseados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path='mnist_r'\n",
    "\n",
    "def list_files(mnist_path):\n",
    "    return [join(mnist_path,f) for f in os.listdir(mnist_path) if isfile(join(mnist_path, f))]\n",
    "\n",
    "def get_images(mnist_path):\n",
    "    #x_train, y_train, x_test, y_test = None, None, None, None \n",
    "    for f in list_files(mnist_path):\n",
    "        if 'train-images' in f:\n",
    "            with gzip.open(f, 'rb') as data:\n",
    "                _ = int.from_bytes(data.read(4), 'big')\n",
    "                num_images = int.from_bytes(data.read(4), 'big')\n",
    "                rows = int.from_bytes(data.read(4), 'big')\n",
    "                cols = int.from_bytes(data.read(4), 'big')\n",
    "                train_images = data.read()\n",
    "                x_train = np.frombuffer(train_images, dtype=np.uint8)\n",
    "                x_train = x_train.reshape((num_images, rows, cols))\n",
    "        elif 'train-labels' in f:\n",
    "            with gzip.open(f, 'rb') as data:\n",
    "                train_labels = data.read()[8:]\n",
    "                y_train = np.frombuffer(train_labels, dtype=np.uint8)\n",
    "        if 't10k-images' in f:\n",
    "            with gzip.open(f, 'rb') as data:\n",
    "                _ = int.from_bytes(data.read(4), 'big')\n",
    "                num_images = int.from_bytes(data.read(4), 'big')\n",
    "                rows = int.from_bytes(data.read(4), 'big')\n",
    "                cols = int.from_bytes(data.read(4), 'big')\n",
    "                test_images = data.read()\n",
    "                x_test = np.frombuffer(test_images, dtype=np.uint8)\n",
    "                x_test = x_test.reshape((num_images, rows, cols))\n",
    "        elif 't10k-labels' in f:\n",
    "            with gzip.open(f, 'rb') as data:\n",
    "                test_labels = data.read()[8:]\n",
    "                y_test = np.frombuffer(test_labels, dtype=np.uint8)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_r\\t10k-images-idx3-ubyte.gz\n",
      "mnist_r\\t10k-labels-idx1-ubyte.gz\n",
      "mnist_r\\train-images-idx3-ubyte.gz\n",
      "mnist_r\\train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "for f in list_files(mnist_path):print(f)\n",
    "#verifico que mi metodo funcione, y me muestre los archivos\n",
    "#deseados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_num, y_train_num, x_test_num, y_test_num=get_images(mnist_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verificamos que cada variable a suar tenga las dimesiones que se han establecido en el database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_num.shape)\n",
    "print(y_train_num.shape)\n",
    "print(x_test_num.shape)\n",
    "print(y_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "jtplot.style(grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #graficas\n",
    "%matplotlib inline\n",
    "#graficas dentro de la libreta de jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sí, red neuronal de 2 capas!!\n",
    "lo anterior sólo lee los archivos binarios para convertirlos en arreglos numpy (eso se puede resumir en 2 líneas, pero hay que aprender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir imagene en vectore y en float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'el .copy() hace una copia literal del arreglo x_test_num'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train_num[:50000].reshape(50000, -1).astype(np.float32)/255\n",
    "y_train = y_train_num[:50000].reshape(50000, 1)\n",
    "#[:50000] sólo extrae los primeros 500000 elementos\n",
    "#reshape es reagruparto en 50000 filas, y en -1 columnas(28*28)\n",
    "#astype es convertirlo en flotante y el /255 para el rango entre 0-1\n",
    "\n",
    "x_val = x_train_num[50000:].reshape(10000, -1).astype(np.float32)/255\n",
    "y_val = y_train_num[50000:].reshape(10000, 1)\n",
    "'''x_val va a almacenar los 10000 datos restantes, es por ello\n",
    "que [50000:] dando a entender que los los datos después del 50000\n",
    "y se usará coo validación'''\n",
    "x_test = x_test_num.copy().reshape(10000, -1).astype(np.float32)/255\n",
    "y_test = y_test_num.copy().reshape(10000, 1)\n",
    "'''el .copy() hace una copia literal del arreglo x_test_num'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(x_train.max())\n",
    "#miramos el valor máximo del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIRAMOS LAS FORMAS (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000, 1)\n",
      "(10000, 784)\n",
      "(10000, 1)\n",
      "(10000, 784)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape) #shape (50000, 784)\n",
    "print(y_train.shape) #shape (50000, 1)\n",
    "\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graficar imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show() #.show() permite mostrar la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen mostrada es un: [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x560 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen mostrada es un: {y_test[rnd_idx]}')\n",
    "plot_number(x_test_num[rnd_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RED NEURONAL 2 CAPAS\n",
    "\n",
    "CREAR MINI-BATCHES\n",
    "minibatches es dividir los datos de entrada en grupos más pequeños para que no consuman tanta memoria (el # de grupos preferiblemente en potencias de 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "        \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explicación de código\n",
    "---create_minibatches(\n",
    "    mb_size=numero de elementos en cada minibatch\n",
    "    x=imagenes o total a etrenar\n",
    "    y=etiquetas a entrenar\n",
    "    shuffle=bandera para un muestreo aleatorio\n",
    ")\n",
    "---x.shape[0] nos da el número total de lo FILAS, NO SUS DIMENSIONES\n",
    "---assert=funcion en python que se utiliza para segurarse de que una expresion sea verdadera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametros iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(input_size, neurons):\n",
    "    \n",
    "    '''\n",
    "    input_size -> elementos de entrada, 784\n",
    "    neurons -> list [200(primera capa), 10(segunda capa)] \n",
    "    con cantidad de neuronas en cada capa\n",
    "    '''\n",
    "    \n",
    "    W1 = np.random.randn(neurons[0], input_size) * 0.001\n",
    "    b1 = np.zeros((neurons[0], 1))\n",
    "    \n",
    "    W2 = np.random.randn(neurons[1], neurons[0]) * 0.001\n",
    "    b2 = np.zeros((neurons[1], 1))\n",
    "    \n",
    "    return {'W1': W1, 'b1':b1, 'W2':W2, 'b2':b2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el init_parameters está bien si sólo usamos 2 capas, pero si estamos hablando de más capas, lo mejor es usar las técnicas xavier o kaiming he\n",
    "en dato caso de que neurons sea de [200,10]\n",
    "neurons[0]=200\n",
    "neurons[1]=10\n",
    "cabe resaltar que W1 o W2 son los valores entre las conexiones de neuronas, y se dan por el arreglo [#neuronas de salida, #neuronas de entrada]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 784)\n",
      "(10, 200)\n",
      "(200, 1)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "parameters = init_parameters(28*28, [200, 10])\n",
    "print(parameters['W1'].shape)\n",
    "print(parameters['W2'].shape)\n",
    "print(parameters['b1'].shape)\n",
    "print(parameters['b2'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.maximum(0,x) sirve para hallar el número mayor, sabemos que el RELU funciona entre 0-1, por lo que, si x es un número negativo, se corta y lo hace igual a 0\n",
    "x=z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(x, parameters, activation_fcn):\n",
    "    '''\n",
    "    x tiene la forma (#pixeles, num samples)\n",
    "    '''\n",
    "    z1 = parameters['W1'] @ x + parameters['b1']\n",
    "    a1 = activation_fcn(z1) # devuel fcn. de activa.\n",
    "    z2 = parameters['W2'] @ a1 + parameters['b2']\n",
    "    \n",
    "    return z2, z1, a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el metodo scores, realiza las operaciones entre capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores,z1, a1 = score(x_train[:64].T, parameters, relu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:64].T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".T nos devuelve las dimensiones transpuestas, es decir, cambiar las filas por columnas y viceversa, veamos el ejemplo:\n",
    "esto se debe a sus dimensiones W[200,784] y x_train[64,784]\n",
    "por lo que NO SE PUEDEN MULTIPLICAR, POR ESO SE USA LA TRANSPUESTA\n",
    "(mirar la diferencia arriba y abajo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 784)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:64].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_scores = np.exp(x)\n",
    "    sum_exp_scores = np.sum(exp_scores, axis=0)\n",
    "    probs = exp_scores/sum_exp_scores\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exp_scores es E elevado a z2(o el último score) (E=euler)\n",
    "axis = 0 es que se sume de manera vertical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_entropy(scores, y, batch_size=64):\n",
    "    probs = softmax(scores)\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "    \n",
    "    return probs, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_entropy es la funcion de pérdida \n",
    "y=y_train\n",
    "--ahora, el squeeze lo que hace es que sólo nos de los datos de las filas (x,y sólo pase los valores de x)(elimine un eje)\n",
    "--el .arrange sirve para seleccionar todas las columnas, es decir, np.arrange(64) da un output de un arrego de 0-64\n",
    "--np.sum() devuelve una suma acumulada de los valores de un array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(probs, x, y, z1, a1, scores, parameters, batch_size=64):\n",
    "    grads = {}\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1 # y-hat - y\n",
    "    dz2 = probs.copy()\n",
    "    \n",
    "    dW2 = dz2 @ a1.T / batch_size\n",
    "    db2 = np.sum(dz2, axis =1, keepdims=True) / batch_size\n",
    "    da1 = parameters['W2'].T @ dz2\n",
    "    \n",
    "    dz1 = da1.copy()\n",
    "    dz1[z1 <= 0 ] =0\n",
    "    \n",
    "    dW1 = dz1 @ x \n",
    "    db1 = np.sum(dz1, axis=1, keepdims=True) \n",
    "    \n",
    "    assert parameters['W1'].shape == dW1.shape, 'W1 no igual forma'\n",
    "    assert parameters['W2'].shape == dW2.shape, 'W2 no igual forma'\n",
    "    assert parameters['b1'].shape == db1.shape, 'b1 no igual forma'\n",
    "    assert parameters['b2'].shape == db2.shape, 'b2 no igual forma'\n",
    "    \n",
    "    grads = {'w1':dW1,  'b1':db1, 'W2':dW2, 'b2':db2}\n",
    "    \n",
    "    return grads\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, cost = x_entropy(scores, y_train[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3025904476542376\n"
     ]
    }
   ],
   "source": [
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = backward(y_hat, x_train[:64], y_train[:64],z1, a1, scores, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x_data, y_data, mb_size=64):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(create_minibatches(mb_size, x_data, y_data)):\n",
    "        scores2, z1, a1 = score(x.T, parameters, relu)\n",
    "        y_hat, cost = x_entropy(scores2, y, batch_size=len(x))\n",
    "        \n",
    "        correct += np.sum(np.argmax(y_hat, axis=0) == y.squeeze())\n",
    "        total += y_hat.shape[1]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---np.argmax=nos calcula el índice del elemento más grande\n",
    "---axis=0 = hace referencia a las filas\n",
    "---x.shape[1] nos da el número total de lo COLUMNAS, NO SUS DIMENSIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, parameters, mb_size=64, learning_rate = 1e-3):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "            scores2, z1, a1 = score(x.T, parameters=parameters, activation_fcn=relu)\n",
    "            y_hat, cost = x_entropy(scores2, y, batch_size=len(x))\n",
    "            grads = backward(y_hat, x, y, z1, a1, scores2, parameters, batch_size=len(x))\n",
    "            \n",
    "            parameters['W1'] = parameters['W1'] - learning_rate*grads['w1']\n",
    "            parameters['b1'] = parameters['b1'] - learning_rate*grads['b1']\n",
    "            parameters['b2'] = parameters['b2'] - learning_rate*grads['b2']\n",
    "            parameters['W2'] = parameters['W2'] - learning_rate*grads['W2']\n",
    "            \n",
    "        print(f'costo es: {cost}, y accuracy: {accuracy(x_val, y_val, mb_size)}')\n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costo es: 0.5175530457136022, y accuracy: 0.8491\n",
      "costo es: 0.4225189965161868, y accuracy: 0.904\n",
      "costo es: 0.2917165477620284, y accuracy: 0.9114\n",
      "costo es: 0.2725427279720397, y accuracy: 0.922\n",
      "costo es: 0.3181255174802123, y accuracy: 0.9272\n",
      "costo es: 0.23355267413333156, y accuracy: 0.9342\n",
      "costo es: 0.2651956029836181, y accuracy: 0.939\n",
      "costo es: 0.1942698306893117, y accuracy: 0.9453\n",
      "costo es: 0.2701051560713508, y accuracy: 0.9485\n",
      "costo es: 0.1903133725169904, y accuracy: 0.9518\n",
      "costo es: 0.17496527025819403, y accuracy: 0.954\n",
      "costo es: 0.19856096578923568, y accuracy: 0.9573\n",
      "costo es: 0.13359997648592623, y accuracy: 0.959\n",
      "costo es: 0.1692186715040601, y accuracy: 0.9603\n",
      "costo es: 0.1629001488263688, y accuracy: 0.9612\n",
      "costo es: 0.16559604292532626, y accuracy: 0.9622\n",
      "costo es: 0.1155850994896493, y accuracy: 0.9639\n",
      "costo es: 0.1207939995271338, y accuracy: 0.9639\n",
      "costo es: 0.12847576014775716, y accuracy: 0.9663\n",
      "costo es: 0.09446144813928606, y accuracy: 0.9666\n"
     ]
    }
   ],
   "source": [
    "mb_size = 512\n",
    "learning_rate = 1e-2\n",
    "epochs = 20\n",
    "parameters = train(epochs=epochs, parameters=parameters, mb_size=mb_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97028"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x_train, y_train, mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9654"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x_test, y_test, mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    scores2, _, _ = score(x, parameters, relu)\n",
    "    return np.argmax(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x560 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el valor predicho es: 8\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test_num[idx])\n",
    "pred = predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'el valor predicho es: {pred}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
